{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec0d43ab-ae52-4663-932f-46c5916eefee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/fpaissan/micromind (from -r requirements.txt (line 4))\n",
      "  Cloning https://github.com/fpaissan/micromind to /tmp/pip-req-build-ign29buv\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/fpaissan/micromind /tmp/pip-req-build-ign29buv\n",
      "  Resolved https://github.com/fpaissan/micromind to commit 8d60ec970ccf19db2b802d96916897b6e7f76b34\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests==2.25.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.25.1)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.11.0.86)\n",
      "Requirement already satisfied: ultralytics==8.0.215 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (8.0.215)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from requests==2.25.1->-r requirements.txt (line 1)) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests==2.25.1->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests==2.25.1->-r requirements.txt (line 1)) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests==2.25.1->-r requirements.txt (line 1)) (2023.5.7)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.215->-r requirements.txt (line 3)) (3.9.2)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.215->-r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.215->-r requirements.txt (line 3)) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.215->-r requirements.txt (line 3)) (6.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.215->-r requirements.txt (line 3)) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.215->-r requirements.txt (line 3)) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.215->-r requirements.txt (line 3)) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.215->-r requirements.txt (line 3)) (4.65.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.215->-r requirements.txt (line 3)) (2.1.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.215->-r requirements.txt (line 3)) (0.13.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.215->-r requirements.txt (line 3)) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.215->-r requirements.txt (line 3)) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics==8.0.215->-r requirements.txt (line 3)) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from micromind==0.2.1->-r requirements.txt (line 4)) (2.6.0)\n",
      "Requirement already satisfied: torchinfo in /opt/conda/lib/python3.10/site-packages (from micromind==0.2.1->-r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from micromind==0.2.1->-r requirements.txt (line 4)) (0.29.1)\n",
      "Requirement already satisfied: accelerate==0.23.0 in /opt/conda/lib/python3.10/site-packages (from micromind==0.2.1->-r requirements.txt (line 4)) (0.23.0)\n",
      "Requirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from micromind==0.2.1->-r requirements.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: loguru in /opt/conda/lib/python3.10/site-packages (from micromind==0.2.1->-r requirements.txt (line 4)) (0.7.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0->micromind==0.2.1->-r requirements.txt (line 4)) (23.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics==8.0.215->-r requirements.txt (line 3)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics==8.0.215->-r requirements.txt (line 3)) (2024.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx->micromind==0.2.1->-r requirements.txt (line 4)) (4.25.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics==8.0.215->-r requirements.txt (line 3)) (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "import digitalhub as dh\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11e1e937-a24b-42ac-b872-e543bdd14cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_object_detection = dh.get_or_create_project(name=\"object_detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae82af4-2ccd-4bf6-b6fd-01c7d51b7337",
   "metadata": {},
   "source": [
    "# Simple YOLO Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7105dac3-e8e5-4747-a4c5-8bbb58ea8a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting functions/train_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile functions/train_model.py\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def train_yolo_model(project, context, params:dict):\n",
    "    # Load a pretrained model\n",
    "    model = YOLO(params[\"base_model\"])\n",
    "    \n",
    "    # Train the model\n",
    "    model.train(data=params[\"data\"], epochs=params[\"epochs\"], imgsz=params[\"imgsz\"])\n",
    "    project.log_model(\n",
    "            name=\"yolo_object_detection\",\n",
    "            kind=\"model\",\n",
    "            framework=\"ultralytics\",\n",
    "            algorithm=\"YOLO\",\n",
    "            source=\"yolo11n.pt\",\n",
    "            metrics={}\n",
    "    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2759f0cd-e0a9-466c-a3ad-bbe5f1cc17c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_fit_fn = project_object_detection.new_function(name=\"object_detection_yolo\",\n",
    "                                kind=\"python\",\n",
    "                                python_version=\"PYTHON3_10\",\n",
    "                                code_src=\"functions/train_model.py\",\n",
    "                                handler=\"train_yolo_model\",\n",
    "                                requirements=[\"requests==2.25.1\", \"opencv-python\", \"ultralytics==8.0.215\", \"git+https://github.com/fpaissan/micromind\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ec769d9-9795-4719-bf6e-4d6ba42f4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"data\": 'Argoverse.yaml', \"epochs\": 1, \"imgsz\":640, \"base_model\": \"yolo11n.pt\"}\n",
    "train_run = model_fit_fn.run(action=\"job\", parameters=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f58d2a-b9d1-4afe-b1d7-b94d41c5b8bf",
   "metadata": {},
   "source": [
    "# Data Drift Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f46dcb0-ede6-4ce1-8831-46cf40f71aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/acelepija/aipc-model/aipc_examples/object_detection_aipc/implementation/src/mmd_drift_detector_backup.zip'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from alibi_detect.cd import MMDDrift\n",
    "from alibi_detect.utils.saving import save_detector, load_detector\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Load CIFAR-10 dataset as the reference dataset\n",
    "def load_cifar10_data():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),  # Resize images to a consistent size\n",
    "        transforms.ToTensor(),        # Convert images to PyTorch tensors\n",
    "    ])\n",
    "    dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=1000, shuffle=True)\n",
    "    X_ref = next(iter(dataloader))[0].numpy()  # Extract the first batch of images\n",
    "    return X_ref\n",
    "\n",
    "# Load datasets\n",
    "X_ref = load_cifar10_data()  # Reference dataset (CIFAR-10)\n",
    "\n",
    "# Initialize the MMD drift detector\n",
    "mmd_detector = MMDDrift(\n",
    "    X_ref,\n",
    "    p_val=0.05,              # Significance level for drift detection\n",
    "    backend='tensorflow',    # Use PyTorch backend\n",
    "    n_permutations=100       # Number of permutations for p-value calculation\n",
    ")\n",
    "# Save the detector for future use\n",
    "folder_detector = \"mmd_drift_detector\" \n",
    "save_detector(mmd_detector, folder_detector)\n",
    "output_zip = \"mmd_drift_detector_backup\"\n",
    "\n",
    "# Create a zip archive\n",
    "shutil.make_archive(output_zip, 'zip', folder_detector)\n",
    "#project.log_artifact(name=\"drift_detector\",\n",
    "#                    kind=\"artifact\",\n",
    "#                    source=f\"model/ts_clustering_{n_clusters}_clusters.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60671dc6-5b47-44eb-99e9-55b0dbfe846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile functions/data_drift_monitor.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load COCO8 dataset as the test dataset\n",
    "def load_coco8_data(coco8_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),  # Resize images to match CIFAR-10 size\n",
    "        transforms.ToTensor(),        # Convert images to PyTorch tensors\n",
    "    ])\n",
    "    images = []\n",
    "    for img_name in os.listdir(coco8_path):\n",
    "        img_path = os.path.join(coco8_path, img_name)\n",
    "        img = Image.open(img_path).convert('RGB')  # Ensure 3 channels (RGB)\n",
    "        img = transform(img)\n",
    "        images.append(img)\n",
    "    X_test = torch.stack(images).numpy()  # Convert list of tensors to numpy array\n",
    "    return X_test\n",
    "\n",
    "\n",
    "def check_data_drift(X_test):\n",
    "    zip_file = \"mmd_drift_detector_backup.zip\" \n",
    "    extract_to = \"mmd_drift_detector\"  \n",
    "    \n",
    "    # Extract the zip file\n",
    "    shutil.unpack_archive(zip_file, extract_to)\n",
    "    \n",
    "    coco8_path = './data/coco8/images/train'    \n",
    "    X_test = load_coco8_data(coco8_path)  \n",
    "    \n",
    "    # Load the detector\n",
    "    loaded_detector = load_detector('mmd_drift_detector')\n",
    "    # Check for drift on the test data\n",
    "    preds = mmd_detector.predict(X_test)\n",
    "    \n",
    "    # Output the results\n",
    "    print(f\"Drift detected: {preds['data']['is_drift']}\")\n",
    "    print(f\"p-value: {preds['data']['p_val']}\")\n",
    "    print(f\"MMD statistic: {preds['data']['distance']}\")\n",
    "    print(preds)\n",
    "    return preds['data']['is_drift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a1cca-fb40-4bf1-8f53-a1a2378106c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9010a0-426e-4c09-a32a-8e4421b1a2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edea4875-df7a-4949-b9da-eb1fe043cf41",
   "metadata": {},
   "source": [
    "# PhiNet YOLO Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6016cf7-4908-40d5-99ef-49efda32046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%% writefile function/train_model_phinet.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from prepare_data import create_loaders, setup_mixup\n",
    "from timm.loss import (\n",
    "    BinaryCrossEntropy,\n",
    "    LabelSmoothingCrossEntropy,\n",
    "    SoftTargetCrossEntropy,\n",
    ")\n",
    "\n",
    "import micromind as mm\n",
    "from micromind.networks import PhiNet, XiNet\n",
    "from micromind.utils import parse_configuration\n",
    "import sys\n",
    "\n",
    "\n",
    "class ImageClassification(mm.MicroMind):\n",
    "    \"\"\"Implements an image classification class. Provides support\n",
    "    for timm augmentation and loss functions.\"\"\"\n",
    "\n",
    "    def __init__(self, hparams, *args, **kwargs):\n",
    "        super().__init__(hparams, *args, **kwargs)\n",
    "\n",
    "        if hparams.model == \"phinet\":\n",
    "            self.modules[\"classifier\"] = PhiNet(\n",
    "                input_shape=hparams.input_shape,\n",
    "                alpha=hparams.alpha,\n",
    "                num_layers=hparams.num_layers,\n",
    "                beta=hparams.beta,\n",
    "                t_zero=hparams.t_zero,\n",
    "                compatibility=False,\n",
    "                divisor=hparams.divisor,\n",
    "                downsampling_layers=hparams.downsampling_layers,\n",
    "                return_layers=hparams.return_layers,\n",
    "                # classification-specific\n",
    "                include_top=True,\n",
    "                num_classes=hparams.num_classes,\n",
    "            )\n",
    "        elif hparams.model == \"xinet\":\n",
    "            self.modules[\"classifier\"] = XiNet(\n",
    "                input_shape=hparams.input_shape,\n",
    "                alpha=hparams.alpha,\n",
    "                gamma=hparams.gamma,\n",
    "                num_layers=hparams.num_layers,\n",
    "                return_layers=hparams.return_layers,\n",
    "                # classification-specific\n",
    "                include_top=True,\n",
    "                num_classes=hparams.num_classes,\n",
    "            )\n",
    "\n",
    "        self.mixup_fn, _ = setup_mixup(hparams)\n",
    "\n",
    "        print(\"Number of parameters for each module:\")\n",
    "        print(self.compute_params())\n",
    "\n",
    "        print(\"Number of MAC for each module:\")\n",
    "        print(self.compute_macs(hparams.input_shape))\n",
    "\n",
    "    def setup_criterion(self):\n",
    "        \"\"\"Setup of the loss function based on augmentation strategy.\"\"\"\n",
    "        # setup loss function\n",
    "        if (\n",
    "            self.hparams.mixup > 0\n",
    "            or self.hparams.cutmix > 0.0\n",
    "            or self.hparams.cutmix_minmax is not None\n",
    "        ):\n",
    "            # smoothing is handled with mixup target transform which outputs sparse,\n",
    "            # soft targets\n",
    "            if self.hparams.bce_loss:\n",
    "                train_loss_fn = BinaryCrossEntropy(\n",
    "                    target_threshold=self.hparams.bce_target_thresh\n",
    "                )\n",
    "            else:\n",
    "                train_loss_fn = SoftTargetCrossEntropy()\n",
    "        elif self.hparams.smoothing:\n",
    "            if self.hparams.bce_loss:\n",
    "                train_loss_fn = BinaryCrossEntropy(\n",
    "                    smoothing=self.hparams.smoothing,\n",
    "                    target_threshold=self.hparams.bce_target_thresh,\n",
    "                )\n",
    "            else:\n",
    "                train_loss_fn = LabelSmoothingCrossEntropy(\n",
    "                    smoothing=self.hparams.smoothing\n",
    "                )\n",
    "        else:\n",
    "            train_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        return train_loss_fn\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"Computes forward step for image classifier.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        batch : List[torch.Tensor, torch.Tensor]\n",
    "            Batch containing the images and labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Predicted class and augmented class. : Tuple[torch.Tensor, torch.Tensor]\n",
    "        \"\"\"\n",
    "        img, target = batch\n",
    "        if not self.hparams.prefetcher:\n",
    "            img, target = img.to(self.device), target.to(self.device)\n",
    "            if self.mixup_fn is not None:\n",
    "                img, target = self.mixup_fn(img, target)\n",
    "\n",
    "        return (self.modules[\"classifier\"](img), target)\n",
    "\n",
    "    def compute_loss(self, pred, batch):\n",
    "        \"\"\"Sets up the loss function and computes the criterion.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        pred : Tuple[torch.Tensor, torch.Tensor]\n",
    "            Predicted class and augmented class.\n",
    "        batch : List[torch.Tensor, torch.Tensor]\n",
    "            Same batch as input to the forward step.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Cost function. : torch.Tensor\n",
    "        \"\"\"\n",
    "        self.criterion = self.setup_criterion()\n",
    "\n",
    "        # taking it from pred because it might be augmented\n",
    "        return self.criterion(pred[0], pred[1])\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configures the optimizes and, eventually the learning rate scheduler.\"\"\"\n",
    "        opt = torch.optim.Adam(self.modules.parameters(), lr=3e-4, weight_decay=0.0005)\n",
    "        return opt\n",
    "\n",
    "\n",
    "def top_k_accuracy(k=1):\n",
    "    \"\"\"\n",
    "    Computes the top-K accuracy.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    k : int\n",
    "       Number of top elements to consider for accuracy.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        accuracy : Callable\n",
    "            Top-K accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    def acc(pred, batch):\n",
    "        if pred[1].ndim == 2:\n",
    "            target = pred[1].argmax(1)\n",
    "        else:\n",
    "            target = pred[1]\n",
    "        _, indices = torch.topk(pred[0], k, dim=1)\n",
    "        correct = torch.sum(indices == target.view(-1, 1))\n",
    "        accuracy = correct.item() / target.size(0)\n",
    "\n",
    "        return torch.Tensor([accuracy]).to(pred[0].device)\n",
    "\n",
    "    return acc\n",
    "\n",
    "def train_model_phinet(project, cfg_file):\n",
    "    hparams = parse_configuration(cfg_file)\n",
    "\n",
    "    train_loader, val_loader = create_loaders(hparams)\n",
    "\n",
    "    exp_folder = mm.utils.checkpointer.create_experiment_folder(\n",
    "        hparams.output_folder, hparams.experiment_name\n",
    "    )\n",
    "\n",
    "    checkpointer = mm.utils.checkpointer.Checkpointer(\n",
    "        exp_folder, hparams=hparams, key=\"loss\"\n",
    "    )\n",
    "\n",
    "    mind = ImageClassification(hparams=hparams)\n",
    "\n",
    "    top1 = mm.Metric(\"top1_acc\", top_k_accuracy(k=1), eval_only=True)\n",
    "    top5 = mm.Metric(\"top5_acc\", top_k_accuracy(k=5), eval_only=True)\n",
    "\n",
    "    mind.train(\n",
    "        epochs=hparams.epochs,\n",
    "        datasets={\"train\": train_loader, \"val\": val_loader},\n",
    "        metrics=[top5, top1],\n",
    "        checkpointer=checkpointer,\n",
    "        debug=hparams.debug,\n",
    "    )\n",
    "\n",
    "    mind.test(datasets={\"test\": val_loader}, metrics=[top1, top5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662f6709-fc49-4d36-a669-b626cdbcbed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
